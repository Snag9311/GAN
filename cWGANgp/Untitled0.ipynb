{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyP5gg1IjwqlYhfQPOBqA8lb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"_DqfTM7cn82L","executionInfo":{"status":"error","timestamp":1619012051369,"user_tz":-540,"elapsed":1330,"user":{"displayName":"‍임상영(대학원학생/일반대학원 디지털애널리틱스 융합협동과정)","photoUrl":"","userId":"17965477251770752751"}},"outputId":"a7a8d661-dd33-4a92-ff20-97ff7271d22e"},"source":["import tensorflow as tf\n","\n","x=tf.experimental.numpy.random.randn(10)\n","x=tf.random.normal([10])\n","type(x.reshape((5,2)))"],"execution_count":10,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-0e3f36aa9e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'reshape'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZgePq4Vpo6d","executionInfo":{"status":"ok","timestamp":1619012302197,"user_tz":-540,"elapsed":1330,"user":{"displayName":"‍임상영(대학원학생/일반대학원 디지털애널리틱스 융합협동과정)","photoUrl":"","userId":"17965477251770752751"}},"outputId":"0ea91105-7127-42b4-be38-441be077a148"},"source":["tf.range(10), np.arange(10), K.arange(10)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>,\n"," array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n"," <tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Ht7yIEYPeo4l","executionInfo":{"status":"error","timestamp":1619016137107,"user_tz":-540,"elapsed":809582,"user":{"displayName":"‍임상영(대학원학생/일반대학원 디지털애널리틱스 융합협동과정)","photoUrl":"","userId":"17965477251770752751"}},"outputId":"c73b1243-f40e-4dd1-df55-21b3754ce2cf"},"source":["from PIL import Image\n","from math import floor\n","import numpy as np\n","import time\n","from functools import partial\n","from random import random\n","import os\n","from keras.datasets import mnist\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n","\n","im_size = 28\n","latent_size = 64\n","emb_size = 32\n","num_labels = 10\n","BATCH_SIZE = 64\n","directory = \"mnist_my\"\n","suff = 'jpg'\n","cmode = 'RGB'\n","channels = 3\n","size_adjusted = False\n","\n","k_images = 3\n","\n","cha = 16\n","\n","# def noise(n):\n","#     return np.random.normal(0.0, 1.0, size = [n, latent_size])\n","\n","# generate points in latent space as input for the generator\n","def noise(n):\n","    # generate points in the latent space\n","    #x_input = tf.experimental.numpy.random.randn(latent_size * n)\n","    z_input = tf.random.normal([n, latent_size])\n","    # reshape into a batch of inputs for the network\n","    #z_input = x_input.reshape(n, latent_size)\n","    # generate labels\n","    return z_input\n","\n","\n","# load fashion mnist images\n","def load_real_samples():\n","    # load dataset\n","    (trainX, trainy), (_, _) = mnist.load_data()\n","    # expand to 3d, e.g. add channels\n","    X = np.expand_dims(trainX, axis=-1)\n","    # convert from ints to floats\n","    X = X.astype('float32')\n","    # scale from [0,255] to [-1,1]\n","    #X = (X - 127.5) / 127.5\n","    X = X / 255.0\n","    return [X, trainy]\n"," \n","# # select real samples\n","def get_batch(dataset, n_samples):\n","    # split into images and labels\n","    images, labels = dataset\n","    # choose random instances\n","    ix = np.random.randint(0, images.shape[0], n_samples)\n","    # select images and labels\n","    X, labels = images[ix], labels[ix]\n","    # generate class labels\n","    #y = ones((n_samples, 1))\n","    return [X, labels]#, y\n","\n","def get_test_batch(num):\n","    \n","    (_, _), (testX, testy) = mnist.load_data()\n","    testX = np.expand_dims(testX, axis=-1)\n","    ix = np.random.randint(0, testX.shape[0], num)\n","    \n","    X, labels = testX[ix], testy[ix]\n","    \n","    return [np.array(X).astype('float32') / 255.0, labels]\n","\n","############\n","## erased code space\n","############\n","\n","\n","# Print iterations progress\n","def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 50, fill = '█'):\n","    \"\"\"\n","    Call in a loop to create terminal progress bar\n","    @params:\n","        iteration   - Required  : current iteration (Int)\n","        total       - Required  : total iterations (Int)\n","        prefix      - Optional  : prefix string (Str)\n","        suffix      - Optional  : suffix string (Str)\n","        decimals    - Optional  : positive number of decimals in percent complete (Int)\n","        length      - Optional  : character length of bar (Int)\n","        fill        - Optional  : bar fill character (Str)\n","    \"\"\"\n","    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n","    filledLength = int(length * iteration // total)\n","    bar = fill * filledLength + '-' * (length - filledLength)\n","    print('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n","    # Print New Line on Complete\n","    if iteration == total:\n","        print()\n","        print()\n","\n","from keras.layers import Conv2D, Dense, AveragePooling2D, Activation, Cropping2D, Dropout, BatchNormalization\n","from keras.layers import Reshape, UpSampling2D, Flatten, Input, add, Lambda, concatenate, LeakyReLU, multiply\n","from keras.layers import GlobalAveragePooling2D, average, Embedding, ZeroPadding2D\n","from keras.models import model_from_json, Model\n","from keras.initializers import VarianceScaling\n","from tensorflow.keras.optimizers import Adam\n","import keras.backend as K\n","import tensorflow as tf\n","\n","def gradient_penalty_loss(y_true, y_pred, averaged_samples, weight):\n","    \n","    def _compute_gradients(tensor, var_list):\n","        grads = tf.gradients(tensor, var_list)\n","        return [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(var_list, grads)]\n","    \n","    gradients = K.gradients(y_pred, averaged_samples)[0]\n","    #gradients = tf.gradients(y_pred, averaged_samples)[0]\n","    #gradients = _compute_gradients(y_pred, averaged_samples)[0]\n","    gradients_sqr = K.square(gradients)\n","    gradient_penalty = K.sum(gradients_sqr,\n","                              axis=K.arange(1, len(gradients_sqr.shape)))\n","\n","    # (weight / 2) * ||grad||^2\n","    # Penalize the gradient norm\n","    return K.mean(gradient_penalty) * (weight / 2)\n","\n","def hinge_d(y_true, y_pred):\n","    return K.mean(K.relu(1.0 - (y_true * y_pred)))\n","\n","def w_loss(y_true, y_pred):\n","    return K.mean(y_true * y_pred)\n","\n","def g_block(inp, fil, u = True):\n","\n","    if u:\n","        out = UpSampling2D(interpolation = 'bilinear')(inp)\n","    else:\n","        out = Activation('linear')(inp)\n","\n","    skip = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n","\n","    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n","    out = LeakyReLU(0.2)(out)\n","\n","    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n","    out = LeakyReLU(0.2)(out)\n","\n","    out = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n","\n","    out = add([out, skip])\n","    out = LeakyReLU(0.2)(out)\n","\n","    return out\n","\n","def d_block(inp, fil, p = True):\n","\n","    skip = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(inp)\n","\n","    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(inp)\n","    out = LeakyReLU(0.2)(out)\n","\n","    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n","    out = LeakyReLU(0.2)(out)\n","\n","    out = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n","\n","    out = add([out, skip])\n","    out = LeakyReLU(0.2)(out)\n","\n","    if p:\n","        out = AveragePooling2D()(out)\n","\n","    return out\n","\n","class GAN(object):\n","\n","    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001):\n","\n","        #Models\n","        self.D = None\n","        self.E = None\n","        self.G = None\n","\n","        self.GE = None\n","        self.EE = None\n","\n","        self.DM = None\n","        self.AM = None\n","\n","        #Config\n","        self.LR = lr\n","        self.steps = steps\n","        self.beta = 0.999\n","\n","        #Init Models\n","        self.discriminator()\n","        self.generator()\n","        self.encoder()\n","\n","        self.EE = model_from_json(self.E.to_json())\n","        self.EE.set_weights(self.E.get_weights())\n","\n","        self.GE = model_from_json(self.G.to_json())\n","        self.GE.set_weights(self.G.get_weights())\n","\n","    def discriminator(self):\n","\n","        if self.D:\n","            return self.D\n","\n","        img_inp = Input(shape = [im_size, im_size, 1])\n","        z_inp = Input(shape = [latent_size])\n","        l_inp = Input(shape = (1,))\n","    \n","        #Label input\n","        n_nodes = 32 * 32\n","        li = Embedding(num_labels, emb_size)(l_inp)\n","        li = Dense(n_nodes)(li)\n","        li = Reshape((32, 32, 1))(li)\n","\n","        #Latent input\n","        l = Dense(512, kernel_initializer = 'he_normal')(z_inp)\n","        l = LeakyReLU(0.2)(l)\n","        l = Dense(512, kernel_initializer = 'he_normal')(l)\n","        l = LeakyReLU(0.2)(l)\n","        l = Dense(512, kernel_initializer = 'he_normal')(l)\n","        l = LeakyReLU(0.2)(l)\n","        \n","        x = ZeroPadding2D((2, 2))(img_inp)\n","        x = concatenate([x, li])  # 32 32 2\n","        x = d_block(x, 2 * cha)  # 16 16 64\n","        x = d_block(x, 4 * cha)  # 8 8 128\n","        x = d_block(x, 8 * cha)  # 4 4 256\n","        x = d_block(x, 16 * cha, p = False)  # 4 4 512\n","\n","        x = Flatten()(x)\n","\n","        x = concatenate([x, l])\n","\n","        x = Dense(16 * cha, kernel_initializer = 'he_normal')(x)\n","        x = LeakyReLU(0.2)(x)\n","\n","        x = Dense(1, kernel_initializer = 'he_normal')(x)\n","\n","        self.D = Model(inputs = [img_inp, z_inp, l_inp], outputs = x)\n","\n","        return self.D\n","\n","    def generator(self):\n","\n","        if self.G:\n","            return self.G\n","\n","        #Inputs\n","        z_inp = Input(shape = [latent_size])\n","        l_inp = Input(shape = (1,))\n","\n","        #Label input\n","        n_nodes = 4 * 4\n","        li = Embedding(num_labels, emb_size)(l_inp)\n","        li = Dense(n_nodes)(li)\n","        li = Reshape((4, 4, 1))(li)\n","\n","        #Actual Model\n","        x = Dense(4*4*16*cha, kernel_initializer = 'he_normal')(z_inp)\n","        x = Reshape([4, 4, 16*cha])(x)\n","        \n","        x = concatenate([x, li])  # 4 4 257\n","\n","        x = g_block(x, 16 * cha, u = False)  # 4 4 256\n","        x = g_block(x, 8 * cha)  # 8 8 128\n","        x = g_block(x, 4 * cha)  # 16 16 64\n","        x = g_block(x, 3 * cha)  # 32 32 47\n","        x = Conv2D(filters = 1, kernel_size = 1, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal')(x)\n","\n","        # cropping\n","        x = Cropping2D((2, 2))(x)\n","        \n","        self.G = Model(inputs = [z_inp, l_inp], outputs = x)\n","\n","        return self.G\n","\n","    def encoder(self):\n","\n","        if self.E:\n","            return self.E\n","\n","        img_inp = Input(shape = [im_size, im_size, 1])\n","        l_inp = Input(shape = (1,))\n","\n","        #Label input\n","        n_nodes = 32 * 32\n","        li = Embedding(num_labels, emb_size)(l_inp)\n","        li = Dense(n_nodes)(li)\n","        li = Reshape((32, 32, 1))(li)\n","\n","        x = ZeroPadding2D((2, 2))(img_inp)\n","        x = concatenate([x, li])  # 32 32 2\n","        x = d_block(x, 2 * cha)  # 16 16 64\n","        x = d_block(x, 4 * cha)  # 8 8 128\n","        x = d_block(x, 8 * cha)  # 4 4 256\n","        x = d_block(x, 16 * cha, p = False)  # 4 4 512\n","\n","        x = Flatten()(x)\n","\n","        x = Dense(16 * cha, kernel_initializer = 'he_normal')(x)\n","        x = LeakyReLU(0.2)(x)\n","\n","        x = Dense(latent_size, kernel_initializer = 'he_normal', bias_initializer = 'zeros')(x)\n","        self.E = Model(inputs = [img_inp, l_inp], outputs = x)\n","\n","        return self.E\n","\n","    def AdModel(self):\n","\n","        #D does not update\n","        self.D.trainable = False\n","        for layer in self.D.layers:\n","            layer.trainable = False\n","\n","        #G does update\n","        self.G.trainable = True\n","        for layer in self.G.layers:\n","            layer.trainable = True\n","\n","        #E does update\n","        self.E.trainable = True\n","        for layer in self.E.layers:\n","            layer.trainable = True\n","\n","        # Fake Latent / Real Image / Real Label\n","        img_r = Input(shape = [im_size, im_size, 1])\n","        l_inp_r = Input(shape=(1,))\n","    \n","        enc_r = self.E([img_r, l_inp_r])\n","        logit_r = self.D([img_r, enc_r, l_inp_r])\n","        \n","        # Real Latent / Fake Image / Fake Label\n","        z = Input(shape = [latent_size])\n","        l_inp_f = Input(shape=(1,))\n","\n","        img_f = self.G([z, l_inp_f])\n","        logit_f = self.D([img_f, z, l_inp_f])\n","\n","        self.AM = Model(inputs = [img_r, z, l_inp_r, l_inp_f], outputs = [logit_r, logit_f])\n","\n","        self.AM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.099), loss = [w_loss, w_loss], experimental_run_tf_function=False)\n","\n","        return self.AM\n","\n","    def DisModel(self):\n","\n","        #D does update\n","        self.D.trainable = True\n","        for layer in self.D.layers:\n","            layer.trainable = True\n","\n","        #G does not update\n","        self.G.trainable = False\n","        for layer in self.G.layers:\n","            layer.trainable = False\n","\n","        #E does update\n","        self.E.trainable = False\n","        for layer in self.E.layers:\n","            layer.trainable = False\n","\n","        # Fake Latent / Real Image / Real Label\n","        img_r = Input(shape = [im_size, im_size, 1])\n","        l_inp_r = Input(shape=(1,))\n","    \n","        enc_r = self.E([img_r, l_inp_r])\n","        logit_r = self.D([img_r, enc_r, l_inp_r])\n","        \n","        # Real Latent / Fake Image / Fake Label\n","        z = Input(shape = [latent_size])\n","        l_inp_f = Input(shape=(1,))\n","\n","        img_f = self.G([z, l_inp_f])\n","        logit_f = self.D([img_f, z, l_inp_f])\n","\n","        #self.DM = Model(inputs = [img_r, z, l_inp_r, l_inp_f], outputs = [logit_r, logit_f, logit_f])\n","        self.DM = Model(inputs = [img_r, z, l_inp_r, l_inp_f], outputs = [logit_r, logit_f])\n","\n","        # Create partial of gradient penalty loss\n","        # For r1, averaged_samples = ri\n","        # For r2, averaged_samples = gf\n","        # Weight of 10 typically works\n","        partial_gp_loss = partial(gradient_penalty_loss, averaged_samples = [img_f, z, l_inp_f], weight = 10)\n","        partial_gp_loss.__name__ = 'partial_gp'  #https://github.com/elastic/apm-agent-python/issues/293\n","        \n","        #Compile With Corresponding Loss Functions\n","        #self.DM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.909), loss=[hinge_d, hinge_d, partial_gp_loss])\n","        self.DM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.909), loss=[hinge_d, hinge_d])\n","\n","        return self.DM\n","\n","    def EMA(self):\n","\n","        start = time.clock()\n","\n","        for i in range(len(self.G.layers)):\n","            up_weight = self.G.layers[i].get_weights()\n","            old_weight = self.GE.layers[i].get_weights()\n","            new_weight = []\n","            for j in range(len(up_weight)):\n","                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n","            self.GE.layers[i].set_weights(new_weight)\n","\n","        for i in range(len(self.E.layers)):\n","            up_weight = self.E.layers[i].get_weights()\n","            old_weight = self.EE.layers[i].get_weights()\n","            new_weight = []\n","            for j in range(len(up_weight)):\n","                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n","            self.EE.layers[i].set_weights(new_weight)\n","\n","        #print(\"Moved Average. \" + str(time.clock() - start) + \"s\")\n","\n","    def MAinit(self):\n","        self.EE.set_weights(self.E.get_weights())\n","        self.GE.set_weights(self.G.get_weights())\n","\n","\n","class BiGAN(object):\n","\n","    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001, silent = True):\n","\n","        self.GAN = GAN(steps = steps, lr = lr, decay = decay)\n","        self.DisModel = self.GAN.DisModel()\n","        self.AdModel = self.GAN.AdModel()\n","\n","        self.lastblip = time.clock()\n","\n","        self.noise_level = 0\n","\n","        self.im = load_real_samples()\n","\n","        self.silent = silent\n","\n","        #Train Generator to be in the middle, not all the way at real. Apparently works better??\n","        self.ones = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n","        self.zeros = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n","        self.nones = -self.ones\n","\n","    def train(self):\n","\n","        #Train Alternating\n","        a = self.train_dis()\n","        b = self.train_gen()\n","\n","        if self.GAN.steps % 10 == 0:\n","            self.GAN.EMA()\n","\n","        if self.GAN.steps == 20000:\n","            self.GAN.MAinit()\n","\n","\n","        #Print info\n","        if self.GAN.steps % 100 == 0 and not self.silent:\n","            print(\"\\n\\nRound \" + str(self.GAN.steps) + \":\")\n","            print(\"D: \" + str(a))\n","            print(\"G: \" + str(b))\n","            s = round((time.clock() - self.lastblip), 4)\n","            steps_per_second = 100 / s\n","            steps_per_minute = steps_per_second * 60\n","            steps_per_hour = steps_per_minute * 60\n","            print(\"Steps/Second: \" + str(round(steps_per_second, 2)))\n","            print(\"Steps/Hour: \" + str(round(steps_per_hour)))\n","            min1k = floor(1000/steps_per_minute)\n","            sec1k = floor(1000/steps_per_second) % 60\n","            print(\"1k Steps: \" + str(min1k) + \":\" + str(sec1k))\n","            self.lastblip = time.clock()\n","            steps_left = 200000 - self.GAN.steps + 1e-7\n","            hours_left = steps_left // steps_per_hour\n","            minutes_left = (steps_left // steps_per_minute) % 60\n","\n","            print(\"Til Completion: \" + str(int(hours_left)) + \"h\" + str(int(minutes_left)) + \"m\")\n","            print()\n","\n","            #Save Model\n","            if self.GAN.steps % 500 == 0:\n","                self.save(floor(self.GAN.steps / 10000))\n","            if self.GAN.steps % 1000 == 0 or (self.GAN.steps % 100 == 0 and self.GAN.steps < 1000):\n","                self.evaluate(floor(self.GAN.steps / 1000))\n","\n","\n","        printProgressBar(self.GAN.steps % 100, 99, decimals = 0)\n","\n","        self.GAN.steps = self.GAN.steps + 1\n","\n","    def train_dis(self):\n","        \n","        train_X, train_y = get_batch(self.im, BATCH_SIZE)\n","        z_inp = noise(BATCH_SIZE)\n","        label_fake = tf.experimental.numpy.random.randint(0, num_labels, BATCH_SIZE)\n","        \n","        #Get Data\n","        # train_data = [self.im.get_batch(BATCH_SIZE), noise(BATCH_SIZE)]\n","        train_data = [train_X, z_inp, train_y, label_fake]\n","\n","        #Train\n","        #d_loss = self.DisModel.train_on_batch(train_data, [self.ones, self.nones, self.ones])\n","        d_loss = self.DisModel.train_on_batch(train_data, [self.ones, self.nones])\n","\n","        return d_loss\n","\n","    def train_gen(self):\n","\n","        train_X, train_y = get_batch(self.im, BATCH_SIZE)\n","        z_inp = noise(BATCH_SIZE)\n","        label_fake = tf.experimental.numpy.random.randint(0, num_labels, BATCH_SIZE)\n","\n","        #Train\n","        train_data = [train_X, z_inp, train_y, label_fake]\n","\n","        g_loss = self.AdModel.train_on_batch(train_data, [self.ones, self.nones])\n","\n","        return g_loss\n","\n","    def evaluate(self, num = 0):\n","\n","        n1 = noise(32)\n","        fake_labels = np.random.randint(0, num_labels, 32)\n","        generated_images = self.GAN.G.predict([n1, fake_labels])\n","\n","        real_images, real_labels = get_test_batch(16)\n","        latent_codes = self.GAN.E.predict([real_images, real_labels], batch_size = BATCH_SIZE)\n","        reconstructed_images = self.GAN.G.predict([latent_codes, real_labels], batch_size = BATCH_SIZE)\n","\n","        print(\"E Mean: \" + str(np.mean(latent_codes)))\n","        print(\"E Std: \" + str(np.std(latent_codes)))\n","        print(\"E Std Featurewise: \" + str(np.mean(np.std(latent_codes, axis = 0))))\n","        print()\n","###########\n","# tmp erased code space\n","###########\n","    def saveModel(self, model, name, num):\n","        json = model.to_json()\n","        with open(\"Models/\"+name+\".json\", \"w\") as json_file:\n","            json_file.write(json)\n","\n","        model.save_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n","\n","    def loadModel(self, name, num):\n","\n","        file = open(\"Models/\"+name+\".json\", 'r')\n","        json = file.read()\n","        file.close()\n","\n","        mod = model_from_json(json)\n","        mod.load_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n","\n","        return mod\n","\n","    def save(self, num): #Save JSON and Weights into /Models/\n","        self.saveModel(self.GAN.G, \"gen\", num)\n","        self.saveModel(self.GAN.D, \"dis\", num)\n","        self.saveModel(self.GAN.E, \"enc\", num)\n","\n","        self.saveModel(self.GAN.GE, \"genMA\", num)\n","        self.saveModel(self.GAN.EE, \"encMA\", num)\n","\n","\n","    def load(self, num): #Load JSON and Weights from /Models/\n","        steps1 = self.GAN.steps\n","\n","        #Load Models\n","        self.GAN.G = self.loadModel(\"gen\", num)\n","        self.GAN.D = self.loadModel(\"dis\", num)\n","        self.GAN.E = self.loadModel(\"enc\", num)\n","\n","        self.GAN.GE = self.loadModel(\"genMA\", num)\n","        self.GAN.EE = self.loadModel(\"encMA\", num)\n","\n","        self.GAN.steps = steps1\n","\n","        self.DisModel = self.GAN.DisModel()\n","        self.AdModel = self.GAN.AdModel()\n","\n","\n","\n","\n","# if __name__ == \"__main__\":\n","model = BiGAN(lr = 0.0001, silent = False)\n","model.evaluate(0)\n","\n","while model.GAN.steps <= 1000:\n","    model.train()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:435: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb723df1560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb724071b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb723df1560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","E Mean: 0.09336724\n","E Std: 0.77219963\n","E Std Featurewise: 0.2372183\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:402: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"],"name":"stderr"},{"output_type":"stream","text":["  |██████████████████████████████████████████████████| 100% \n","\n","\n","\n","Round 100:\n","D: [0.2808283865451813, 0.2681701183319092, 0.01265828125178814]\n","G: [7.432832717895508, 5.520326137542725, 1.9125065803527832]\n","Steps/Second: 0.13\n","Steps/Hour: 470\n","1k Steps: 127:40\n","Til Completion: 425h21m\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:466: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:475: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"],"name":"stderr"},{"output_type":"stream","text":["E Mean: -0.3513738\n","E Std: 2.26091\n","E Std Featurewise: 0.4488153\n","\n","  |██████████████████████████████████████████████████| 100% \n","\n","\n","\n","Round 200:\n","D: [1.7820934057235718, 0.0, 1.7820934057235718]\n","G: [3.7569432258605957, 0.86772620677948, 2.889216899871826]\n","Steps/Second: 0.13\n","Steps/Hour: 475\n","1k Steps: 126:11\n","Til Completion: 420h12m\n","\n","E Mean: 0.2846715\n","E Std: 1.3066609\n","E Std Featurewise: 0.28642145\n","\n","  |██████████████████████████████████████████████████| 100% \n","\n","\n","\n","Round 300:\n","D: [1.2337967157363892, 0.018081584945321083, 1.2157151699066162]\n","G: [2.4081199169158936, -0.6714942455291748, 3.0796141624450684]\n","Steps/Second: 0.13\n","Steps/Hour: 473\n","1k Steps: 126:55\n","Til Completion: 422h26m\n","\n","E Mean: -0.2665979\n","E Std: 1.6190413\n","E Std Featurewise: 0.42011935\n","\n","  |██████████████████████████████████████████████████| 100% \n","\n","\n","\n","Round 400:\n","D: [1.1126668453216553, 0.1878311187028885, 0.9248356819152832]\n","G: [1.9985939264297485, 0.6559320688247681, 1.3426618576049805]\n","Steps/Second: 0.13\n","Steps/Hour: 469\n","1k Steps: 128:2\n","Til Completion: 425h57m\n","\n","E Mean: -0.070098355\n","E Std: 1.2704806\n","E Std Featurewise: 0.27650493\n","\n","  |██████████████████████████████████████████████████| 100% \n","\n","\n","\n","Round 500:\n","D: [1.492398738861084, 1.1025071144104004, 0.38989168405532837]\n","G: [1.782308578491211, 1.2417372465133667, 0.5405713319778442]\n","Steps/Second: 0.13\n","Steps/Hour: 467\n","1k Steps: 128:28\n","Til Completion: 427h12m\n","\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9a42b9a7d501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-9a42b9a7d501>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;31m#Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-9a42b9a7d501>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Save JSON and Weights into /Models/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gen\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"enc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-9a42b9a7d501>\u001b[0m in \u001b[0;36msaveModel\u001b[0;34m(self, model, name, num)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models/gen.json'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"it7PZEx82s8P","executionInfo":{"status":"ok","timestamp":1618998925402,"user_tz":-540,"elapsed":770,"user":{"displayName":"‍임상영(대학원학생/일반대학원 디지털애널리틱스 융합협동과정)","photoUrl":"","userId":"17965477251770752751"}},"outputId":"f26095cb-3ed5-4235-eb54-c1f1731d6af9"},"source":["import numpy as np\n","\n","np.random.randint(0, 10, 10)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 4, 1, 1, 7, 9, 5, 7, 3, 0])"]},"metadata":{"tags":[]},"execution_count":6}]}]}